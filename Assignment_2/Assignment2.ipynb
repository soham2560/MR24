{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roll numbers:\n",
    "\n",
    "\n",
    "- Sarthak Mishra: 2023701027 \n",
    "- Samaksh Ujjawal: 2024702013\n",
    "- Rohit Pawar: 2024701025\n",
    "- Soham Patil: 2024701005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Instructions\n",
    " * Fill in the roll-number in the cell above.\n",
    " * Code must be submitted in Python in jupyter notebooks. We highly recommend using anaconda/miniconda distribution or at the minimum, virtual environments for this assignment.\n",
    " * All the code and result files should be uploaded in the github classroom.\n",
    " *  Most of the questions require you to **code your own functions** unless there is a need to call in the abilities of the mentioned libraries, such as Visualisation from Open3D. Make sure your code is modular since you will be reusing them for future assignments. All the functions related to transformation matrices, quaternions, and 3D projection are expected to be coded by you.\n",
    " *  All the representations are expected to be in a right-hand coordinate system.\n",
    "<!--  * Answer to the descriptive questions should be answered in your own words. Copy-paste answers will lead to penalty. -->\n",
    " * You could split the Jupyter Notebook cells where TODO is written, but please try to avoid splitting/changing the structure of other cells.\n",
    " * All the visualization should be done inside the notebook unless specified otherwise.\n",
    " * Plagiarism will lead to heavy penalty.\n",
    " * Commit the notebooks in the repo and any other results files under the result folder in the GitHub Classroom repo. \n",
    " * This is a group assignment. Discussions are encouraged but any sharing of code among different teams will be penalized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 1: ICP with SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Perform Procrustes alignmenton two point clouds with (given) known correspondences. (5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let X be your point cloud observed from the initial pose P1. You then transform it to a new pose P2. Now you wish to apply ICP to recover transformation between (X & P1) and (X & P2).\n",
    "\n",
    "Use toothless.ply point cloud and perform the alignment between the two point clouds using procrustes alignment. Your task is to write a function that takes two point clouds as input wherein the corresponding points between the two point clouds are located at the same index and returns the transformation matrix between them. Compute the alignment error after aligning the two point clouds.\n",
    "\n",
    "<b>Use root mean squared error (RSME) as the alignment error metric.</b>\n",
    "\n",
    "Make sure your code is modular as we will use this function in the next sub-part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will again use our own getTransform function to generate the 4x4 Transformation matrix to transform the pointcloud to P2, so make sure your code works for any general Transformation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Transform Implementation\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def alpha_rot(alpha):\n",
    "    return np.array([\n",
    "        [   1.0,    0.0,                0.0             ],\n",
    "        [   0.0,    math.cos(alpha),   -math.sin(alpha) ],\n",
    "        [   0.0,    math.sin(alpha),    math.cos(alpha) ]\n",
    "        ],dtype=np.float32)\n",
    "\n",
    "def beta_rot(beta):\n",
    "    return np.array([\n",
    "        [   math.cos(beta),     0.0,    math.sin(beta)  ],\n",
    "        [   0.0,                1.0,    0.0             ],\n",
    "        [  -math.sin(beta),     0.0,    math.cos(beta)  ]\n",
    "        ],dtype=np.float32)\n",
    "\n",
    "def gamma_rot(gamma):\n",
    "    return np.array([\n",
    "        [   math.cos(gamma),   -math.sin(gamma),    0.0 ],\n",
    "        [   math.sin(gamma),    math.cos(gamma),    0.0 ],\n",
    "        [   0.0,                0.0,                1.0 ]\n",
    "        ],dtype=np.float32)\n",
    "        \n",
    "def euler2rm(alpha, beta, gamma):\n",
    "    return np.matmul(alpha_rot(alpha),np.matmul(beta_rot(beta),gamma_rot(gamma)))\n",
    "\n",
    "def getTransform():\n",
    "    R = euler2rm(np.random.uniform(0, 2 * np.pi),\n",
    "                 np.random.uniform(0, 2 * np.pi),\n",
    "                 np.random.uniform(0, 2 * np.pi))\n",
    "    T = np.array([\n",
    "        [np.random.uniform(-500, 500)],\n",
    "        [np.random.uniform(-500, 500)],\n",
    "        [np.random.uniform(-500, 500)]\n",
    "    ])\n",
    "    \n",
    "    transformation_matrix = np.eye(4)\n",
    "    transformation_matrix[:3, :3] = R\n",
    "    transformation_matrix[:3, 3] = T.flatten()\n",
    "    \n",
    "    return transformation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.1 Solution\n",
    "import open3d as o3d\n",
    "\n",
    "def invert_transform(matrix):\n",
    "    rotation_matrix = matrix[:3, :3]\n",
    "    translation_vector = matrix[:3, 3]\n",
    "\n",
    "    inv_rotation_matrix = np.transpose(rotation_matrix)\n",
    "    inv_translation_vector = -np.matmul(inv_rotation_matrix, translation_vector)\n",
    "\n",
    "    inv_matrix = np.eye(4)\n",
    "    inv_matrix[:3, :3] = inv_rotation_matrix\n",
    "    inv_matrix[:3, 3] = inv_translation_vector\n",
    "    \n",
    "    return inv_matrix\n",
    "\n",
    "def transform_point_cloud(point_cloud, transformation_matrix, downsample=1.0):\n",
    "    if downsample < 1.0:\n",
    "        indices = np.arange(0, point_cloud.shape[0], int(1.0 / downsample))\n",
    "        point_cloud = point_cloud[indices]\n",
    "\n",
    "    rotated_points = np.dot(point_cloud, transformation_matrix[:3, :3].T)\n",
    "    transformed_points = rotated_points + transformation_matrix[:3, 3]\n",
    "\n",
    "    return transformed_points\n",
    "\n",
    "def icp_with_svd(pcl0, pcl1, transform):\n",
    "    pcl1_transformed = transform_point_cloud(pcl1, transform)\n",
    "    centroid_pcl0 = np.mean(pcl0, axis=0)\n",
    "    centroid_pcl1 = np.mean(pcl1_transformed, axis=0)\n",
    "    centered_pcl0 = pcl0 - centroid_pcl0\n",
    "    centered_pcl1 = pcl1_transformed - centroid_pcl1\n",
    "    H = centered_pcl0.T @ centered_pcl1\n",
    "    U, D, Vt = np.linalg.svd(H)\n",
    "    R = U @ Vt\n",
    "    if np.linalg.det(R) < 0:\n",
    "        R[:, 2] *= -1\n",
    "    t = centroid_pcl0 - R @ centroid_pcl1\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = R\n",
    "    T[:3, 3] = t\n",
    "    \n",
    "    return T\n",
    "\n",
    "pcl = o3d.io.read_point_cloud('data/toothless.ply')\n",
    "pcl_array = np.array(pcl.points)\n",
    "\n",
    "transform0 = getTransform()\n",
    "transform1 = getTransform()\n",
    "\n",
    "downsample = 1\n",
    "\n",
    "pcl0 = transform_point_cloud(pcl_array, transform0, downsample)\n",
    "pcl1 = transform_point_cloud(pcl_array + np.random.normal(0.0, 1, pcl_array.shape), transform1, downsample)\n",
    "\n",
    "pcl0_geom = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(pcl0))\n",
    "frame0 = o3d.geometry.TriangleMesh.create_coordinate_frame(size=100.0, origin=[0, 0, 0])\n",
    "pcl0_geom.paint_uniform_color([1.0, 0.0, 0.0])\n",
    "pcl1_geom = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(pcl1))\n",
    "frame1 = o3d.geometry.TriangleMesh.create_coordinate_frame(size=100.0, origin=[0, 0, 0])\n",
    "pcl1_geom.paint_uniform_color([0.0, 0.0, 1.0])\n",
    "\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "vis.add_geometry(pcl0_geom)\n",
    "vis.add_geometry(frame0)\n",
    "vis.add_geometry(pcl1_geom)\n",
    "vis.add_geometry(frame1)\n",
    "\n",
    "vis.poll_events()\n",
    "vis.update_renderer()\n",
    "\n",
    "opti_transform = np.eye(4)\n",
    "\n",
    "svd_transform = icp_with_svd(pcl0, pcl1, opti_transform)\n",
    "opti_transform = svd_transform @ opti_transform\n",
    "\n",
    "pcl1_geom.points = o3d.utility.Vector3dVector(transform_point_cloud(pcl1, opti_transform))\n",
    "frame1.vertices = o3d.utility.Vector3dVector(transform_point_cloud(np.array(frame0.vertices), opti_transform))\n",
    "vis.update_geometry(pcl1_geom)\n",
    "vis.update_geometry(frame1)\n",
    "vis.poll_events()\n",
    "vis.update_renderer()\n",
    "error = np.linalg.norm(pcl0-transform_point_cloud(pcl1,opti_transform))/pcl0.shape[0]\n",
    "\n",
    "if error < 2e-2:\n",
    "    pcl0_geom.paint_uniform_color([0.0, 1.0, 0.0])\n",
    "    pcl1_geom.paint_uniform_color([0.0, 1.0, 0.0])\n",
    "    vis.update_geometry(pcl0_geom)\n",
    "    vis.update_geometry(pcl1_geom)\n",
    "    vis.update_geometry(frame1)\n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()\n",
    "    print(f\"Converged in 1 iteration(obviously) with {error} error.\")\n",
    "    print(\"Expected transformation matrix:\")\n",
    "    print(np.array_str(transform0 @ invert_transform(transform1), precision=4, suppress_small=True))\n",
    "    print(\"Final transformation matrix:\")\n",
    "    print(np.array_str(opti_transform, precision=4, suppress_small=True))\n",
    "else:\n",
    "    print(\"Failed to converge\")\n",
    "vis.run()\n",
    "vis.destroy_window()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Implement ICP algorithm with unknown correspondences. (5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to write a function that implements ICP and takes two point clouds as input wherein the correspondances are unknown. Visualize the pointclouds and plot their individual coordinate frames as you perform ICP over them. Compute the alignment error in each iteration. \n",
    "\n",
    "Refer to Shubodh's notes to compute correspondences: https://saishubodh.notion.site/Mobile-Robotics-Navigating-from-Theory-to-Application-0b65a9c20edd4081978f4ffad917febb?p=a25686ce1a11409d838d47bcac43ab4b&pm=s#bb9aaf2e316b4db3b399df1742f0444c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.2 Solution\n",
    "\n",
    "def compute_correspondences(pcl0, pcl1, transform):\n",
    "    transformed_pcl1 = transform_point_cloud(pcl1, transform)\n",
    "    ci = []\n",
    "    for i in range(pcl0.shape[1]):\n",
    "        closest_idx = np.argmin(np.linalg.norm(transformed_pcl1 - pcl0[:, i].reshape(pcl0.shape[0], 1), axis=0))\n",
    "        ci.append(closest_idx)\n",
    "        transformed_pcl1[:, closest_idx] = np.inf\n",
    "    ci = np.array(ci)\n",
    "    matched_pcl1 = pcl1[:, ci]\n",
    "    return matched_pcl1\n",
    "\n",
    "pcl = o3d.io.read_point_cloud('data/toothless.ply')\n",
    "pcl_array = np.array(pcl.points)\n",
    "\n",
    "transform0 = getTransform()\n",
    "transform1 = getTransform()\n",
    "\n",
    "downsample = 1\n",
    "\n",
    "pcl0 = transform_point_cloud(pcl_array, transform0, downsample)\n",
    "pcl1 = transform_point_cloud(pcl_array + np.random.normal(0.0, 1, pcl_array.shape), transform1, downsample)\n",
    "\n",
    "pcl0_geom = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(pcl0))\n",
    "frame0 = o3d.geometry.TriangleMesh.create_coordinate_frame(size=100.0, origin=[0, 0, 0])\n",
    "pcl0_geom.paint_uniform_color([1.0, 0.0, 0.0])\n",
    "pcl1_geom = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(pcl1))\n",
    "frame1 = o3d.geometry.TriangleMesh.create_coordinate_frame(size=100.0, origin=[0, 0, 0])\n",
    "pcl1_geom.paint_uniform_color([0.0, 0.0, 1.0])\n",
    "\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "vis.add_geometry(pcl0_geom)\n",
    "vis.add_geometry(frame0)\n",
    "vis.add_geometry(pcl1_geom)\n",
    "vis.add_geometry(frame1)\n",
    "\n",
    "vis.poll_events()\n",
    "vis.update_renderer()\n",
    "opti_transform = np.eye(4)\n",
    "for i in range(50):\n",
    "    matched_pcl1 = compute_correspondences(pcl0, pcl1, opti_transform)\n",
    "    svd_transform = icp_with_svd(pcl0, matched_pcl1, opti_transform)\n",
    "    opti_transform = svd_transform @ opti_transform\n",
    "    pcl1_geom.points = o3d.utility.Vector3dVector(transform_point_cloud(pcl1, opti_transform))\n",
    "    frame1.vertices = o3d.utility.Vector3dVector(transform_point_cloud(np.array(frame0.vertices), opti_transform))\n",
    "    vis.update_geometry(pcl1_geom)\n",
    "    vis.update_geometry(frame1)\n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()\n",
    "    error = np.linalg.norm(pcl0-transform_point_cloud(pcl1,opti_transform))/pcl0.shape[0]\n",
    "    if error < 2e-2:\n",
    "        pcl0_geom.paint_uniform_color([0.0, 1.0, 0.0])\n",
    "        pcl1_geom.paint_uniform_color([0.0, 1.0, 0.0])\n",
    "        vis.update_geometry(pcl0_geom)\n",
    "        vis.update_geometry(pcl1_geom)\n",
    "        vis.update_geometry(frame1)\n",
    "        vis.poll_events()\n",
    "        vis.update_renderer()\n",
    "        print(f\"Converged in {i+1} iterations with {error} error.\")\n",
    "        print(\"Expected transformation matrix:\")\n",
    "        print(np.array_str(transform0 @ invert_transform(transform1), precision=4, suppress_small=True))\n",
    "        print(\"Final transformation matrix:\")\n",
    "        print(np.array_str(opti_transform, precision=4, suppress_small=True))\n",
    "        break\n",
    "    print(error)\n",
    "\n",
    "if error > 2e-2:\n",
    "    print(\"Failed to converge\")\n",
    "vis.run()\n",
    "vis.destroy_window()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 2: ICP with Lie Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Predict the Transformation matrix between 2 point clouds with known correspondences (15 Points)\n",
    "Perform the same task as 1.1 using Lie Group Optimization from scratch to predict the transformation between the 2 point clouds.\n",
    "\n",
    "Refer: https://saishubodh.notion.site/Mobile-Robotics-Navigating-from-Theory-to-Application-0b65a9c20edd4081978f4ffad917febb?p=ee55fe5689794693910ab7861bef067b&pm=s#7b82d84766a84b63b91d859579e4886b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.1 Solution\n",
    "def skew(vector):\n",
    "    x, y, z = vector.ravel()\n",
    "    \n",
    "    return np.array([\n",
    "        [ 0, -z,  y],\n",
    "        [ z,  0, -x],\n",
    "        [-y,  x,  0]\n",
    "    ])\n",
    "\n",
    "def icp_with_lie(pcl0, pcl1, guess_transform):\n",
    "    pcl1_transformed = transform_point_cloud(pcl1, guess_transform)\n",
    "    \n",
    "    residuals = (pcl1_transformed - pcl0).reshape(-1,1)\n",
    "\n",
    "    jacobian = np.zeros((pcl1.shape[0] * 3, 6))\n",
    "\n",
    "    for j in range(pcl1_transformed.shape[0]):\n",
    "        jacobian[3 * j: 3 * j + 3, 0:3] = np.eye(3)\n",
    "        jacobian[3 * j: 3 * j + 3, 3:6] = -skew(pcl1_transformed[j])\n",
    "\n",
    "    delta_x = -(np.linalg.pinv(jacobian.T @ jacobian) @ jacobian.T @ residuals)\n",
    "    return delta_x\n",
    "\n",
    "def se3_exp(xi):\n",
    "    w = xi[3:]\n",
    "    v = xi[:3]\n",
    "    theta = np.linalg.norm(w)\n",
    "    if theta < 1e-6:\n",
    "        R = np.eye(3)\n",
    "        J = np.eye(3)\n",
    "    else:\n",
    "        axis = w / theta\n",
    "        skew_axis = skew(axis)\n",
    "        R = np.eye(3) + np.sin(theta) * skew_axis + (1 - np.cos(theta)) * (skew_axis @ skew_axis)\n",
    "        J = np.eye(3) + ((1 - np.cos(theta)) / (theta**2)) * (skew_axis @ skew_axis) + \\\n",
    "            (theta - np.sin(theta)) / (theta**3) * (skew_axis @ skew_axis @ skew_axis)\n",
    "\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = R\n",
    "    T[:3, 3] = (J @ v).flatten()\n",
    "    return T\n",
    "\n",
    "pcl = o3d.io.read_point_cloud('data/toothless.ply')\n",
    "pcl_array = np.array(pcl.points)\n",
    "\n",
    "transform0 = getTransform()\n",
    "transform1 = getTransform()\n",
    "\n",
    "downsample = 0.1\n",
    "\n",
    "pcl0 = transform_point_cloud(pcl_array, transform0, downsample)\n",
    "pcl1 = transform_point_cloud(pcl_array + np.random.normal(0.0, 1, pcl_array.shape), transform1, downsample)\n",
    "\n",
    "pcl0_geom = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(pcl0))\n",
    "frame0 = o3d.geometry.TriangleMesh.create_coordinate_frame(size=100.0, origin=[0, 0, 0])\n",
    "pcl0_geom.paint_uniform_color([1.0, 0.0, 0.0])\n",
    "pcl1_geom = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(pcl1))\n",
    "frame1 = o3d.geometry.TriangleMesh.create_coordinate_frame(size=100.0, origin=[0, 0, 0])\n",
    "pcl1_geom.paint_uniform_color([0.0, 0.0, 1.0])\n",
    "\n",
    "vis = o3d.visualization.Visualizer()\n",
    "vis.create_window()\n",
    "\n",
    "vis.add_geometry(pcl0_geom)\n",
    "vis.add_geometry(frame0)\n",
    "vis.add_geometry(pcl1_geom)\n",
    "vis.add_geometry(frame1)\n",
    "\n",
    "vis.poll_events()\n",
    "vis.update_renderer()\n",
    "\n",
    "opti_transform = getTransform()\n",
    "\n",
    "for i in range(20):\n",
    "    delta_epsilon = icp_with_lie(pcl0, pcl1, opti_transform)\n",
    "    opti_transform = se3_exp(delta_epsilon) @ opti_transform\n",
    "    pcl1_geom.points = o3d.utility.Vector3dVector(transform_point_cloud(pcl1,opti_transform))\n",
    "    frame1.vertices = o3d.utility.Vector3dVector(transform_point_cloud(np.array(frame0.vertices),opti_transform))\n",
    "    vis.update_geometry(pcl1_geom)\n",
    "    vis.update_geometry(frame1)\n",
    "    vis.poll_events()\n",
    "    vis.update_renderer()\n",
    "    error = np.linalg.norm(transform_point_cloud(pcl1,opti_transform) - pcl0)/pcl0.shape[0]\n",
    "    print(error)\n",
    "    if error < 3e-2:\n",
    "        pcl0_geom.paint_uniform_color([0.0, 1.0, 0.0])\n",
    "        pcl1_geom.paint_uniform_color([0.0, 1.0, 0.0])\n",
    "        vis.update_geometry(pcl0_geom)\n",
    "        vis.update_geometry(pcl1_geom)\n",
    "        vis.update_geometry(frame1)\n",
    "        vis.poll_events()\n",
    "        vis.update_renderer()\n",
    "        print(f\"Converged in {i} iterations with {error} error.\")\n",
    "        print(\"Expected transformation matrix:\")\n",
    "        print(np.array_str(transform0 @ invert_transform(transform1), precision=4, suppress_small=True))\n",
    "        print(\"Final transformation matrix:\")\n",
    "        print(np.array_str(opti_transform, precision=4, suppress_small=True))\n",
    "        break\n",
    "\n",
    "if error > 3e-2:\n",
    "    print(\"Failed to converge\")\n",
    "vis.run()\n",
    "vis.destroy_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 3: Pose Graph Optimization with G2O\n",
    "### Objective (5 Points)\n",
    "A robot is travelling in a oval trajectory. It is equipped with wheel odometry for odometry information and RGBD sensors for loop closure information. Due to noise in wheel odometry it generates a noisy estimate of the trajectory. Our task is to use loop closure pairs to correct the drift.\n",
    "\n",
    "We pose this problem as a pose graph optimization problem. In our graph, poses are the vertices and constraints are the edges. \n",
    "\n",
    "References:\n",
    "\n",
    "1.) Class notes: https://saishubodh.notion.site/G2O-Edge-Types-d9f9ff63c77c4ceeb84b1e49085004e3\n",
    "\n",
    "2.) Cyrill Stachniss lecture: https://www.youtube.com/watch?v=uHbRKvD8TWg "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given: \n",
    "In practical scenarios, we'd obtain the following from our sensors after some post-processing:\n",
    "\n",
    "1. Initial position\n",
    "2. Odometry Contraints/Edges: This \"edge\" information tells us relative transformation between two nodes. These two nodes are consecutive in the case of Odometry but not in the case of Loop Closure (next point).\n",
    "3. Loop Closure Contraints/Edges: Remember that while optimizing, you have another kind of \"anchor\" edge as you've seen in 1. solved example.\n",
    "\n",
    "You have been given a text file named `edges.txt` (in `data/`) which has all the above 3 and it follows G2O's format (as explained in class, [link here](https://saishubodh.notion.site/G2O-Edge-Types-d9f9ff63c77c4ceeb84b1e49085004e3) ). The ground truth is `gt.txt`.\n",
    "\n",
    "Install g2o as mentioned in `g2o.ipynb` and optimise `edges.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given Helper Functions\n",
    "def readVertex(fileName):\n",
    "    f = open(fileName, 'r')\n",
    "    A = f.readlines()\n",
    "    f.close()\n",
    "\n",
    "    x_arr = []\n",
    "    y_arr = []\n",
    "    theta_arr = []\n",
    "\n",
    "    for line in A:\n",
    "        if \"VERTEX_SE2\" in line:\n",
    "            (ver, ind, x, y, theta) = line.split()\n",
    "            x_arr.append(float(x))\n",
    "            y_arr.append(float(y))\n",
    "            theta_arr.append(float(theta.rstrip('\\n')))\n",
    "\n",
    "    return np.array([x_arr, y_arr, theta_arr])\n",
    "\n",
    "def readEdge(fileName):\n",
    "    f = open(fileName, 'r')\n",
    "    A = f.readlines()\n",
    "    f.close()\n",
    "\n",
    "    ind1_arr = []\n",
    "    ind2_arr = []\n",
    "    del_x = []\n",
    "    del_y = []\n",
    "    del_theta = []\n",
    "\n",
    "    for line in A:\n",
    "        if \"EDGE_SE2\" in line:\n",
    "            (edge, ind1, ind2, dx, dy, dtheta, _, _, _, _, _, _) = line.split()\n",
    "            ind1_arr.append(int(ind1))\n",
    "            ind2_arr.append(int(ind2))\n",
    "            del_x.append(float(dx))\n",
    "            del_y.append(float(dy))\n",
    "            del_theta.append(float(dtheta))\n",
    "\n",
    "    return (np.array( ind1_arr), np.array(ind2_arr), np.array(del_x), np.array(del_y), np.array(del_theta))\n",
    "\n",
    "def draw(X, Y, THETA):\n",
    "    ax = plt.subplot(111)\n",
    "    ax.plot(X, Y, 'ro')\n",
    "    plt.plot(X, Y, 'c-')\n",
    "\n",
    "    for i in range(len(THETA)):\n",
    "        x2 = 0.25*math.cos(THETA[i]) + X[i]\n",
    "        y2 = 0.25*math.sin(THETA[i]) + Y[i]\n",
    "        plt.plot([X[i], x2], [Y[i], y2], 'g->')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground Truth Data\n",
    "input_file = \"./data/gt.txt\"\n",
    "gt_vertex = readVertex(input_file)\n",
    "gt_edges = readEdge(input_file)\n",
    "print(gt_vertex.shape)\n",
    "draw(gt_vertex[0],gt_vertex[1],gt_vertex[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "#code to generate the g2o file for edges.txt\n",
    "input_file = \"./data/edges.txt\"\n",
    "output_file = \"./data/edges.g2o\"\n",
    "\n",
    "out = open(output_file, \"w\")\n",
    "\n",
    "init = readVertex(input_file)\n",
    "x = np.zeros(120)\n",
    "y = np.zeros(120)\n",
    "theta = np.zeros(120)\n",
    "x[0] = init[0]\n",
    "y[0] = init[1]\n",
    "theta[0] = init[2]\n",
    "\n",
    "ind1, ind2, dx, dy, dtheta = readEdge(input_file)\n",
    "info_x_y_theta = \"500.0 0.0 0.0 500.0 0.0 500.0\"\n",
    "\n",
    "print(len(ind1))\n",
    "\n",
    "for i in range(len(x)-1):\n",
    "    # USE MODEL TO CALCULATE VERTICES AND PROCEED\n",
    "    # WAIT FOR MODEL TO BE GIVEN\n",
    "    pass \n",
    "\n",
    "# for i in range(len(x)):\n",
    "#     out.write(\"VERTEX_SE2\" + \" \" + str(i) + \" \" + str(x[i]) + \" \" + str(y[i]) + \" \" + str(theta[i]) + \"\\n\")\n",
    "\n",
    "# for i in range(len(ind1)):\n",
    "#     out.write(\"EDGE_SE2\" + \" \" + str(ind1[i]) + \" \" + str(ind2[i]) + \" \" + str(dx[i]) + \" \" + str(dy[i]) + \" \" + str(dtheta[i]) + \" \" + info_x_y_theta + \"\\n\")\n",
    "\n",
    "\n",
    "# out.write(\"FIX 0\"+\"\\n\")\n",
    "\n",
    "# print(np.size(x))\n",
    "# draw(x,y,theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to optimise this data with g2o\n",
    "def optimize():\n",
    "    cmd = \"g2o -o ./data/optimal.g2o ./data/edges.g2o\"\n",
    "    os.system(cmd)\n",
    "optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimised Data\n",
    "input_file = \"./data/optimal.g2o\"\n",
    "gt_vertex = readVertex(input_file)\n",
    "gt_edges = readEdge(input_file)\n",
    "print(gt_vertex.shape)\n",
    "draw(gt_vertex[0],gt_vertex[1],gt_vertex[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to view in g2o_viewer\n",
    "\n",
    "os.system(\"g2o_viewer ./data/optimal.g2o\")\n",
    "os.system(\"g2o_viewer ./data/gt.g2o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evo (10 Points)\n",
    "We need a measure of how good the trajectory is. The error/loss used earlier doesn't tell us much about how the trajectory differs from the ground truth. Here, we try to do just this - compute error metrics. Rather than computing these from scratch, we will just Evo - https://github.com/MichaelGrupp/evo/.\n",
    "\n",
    "Look at the absolute pose error (APE) and relative pose error (RPE). What do they capture and how are they calculated (descriptive answer)? How do these metrics differ in methodology? Can we determine if the error is more along the x/y axis?\n",
    "\n",
    "Answer the above questions and report errors for the obtained trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commands to convert to Kitti\n",
    "\n",
    "# python3 ./misc/g2o_to_kitti.py ./data/gt.g2o ./data/gt.kitti\n",
    "\n",
    "# python3 ./misc/g2o_to_kitti.py ./data/optimal.g2o ./data/optimal.kitti\n",
    "\n",
    "# python3 ./misc/g2o_to_kitti.py ./data/edges.g2o ./data/edges.kitti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commands to generate RPE Error Graphs\n",
    "# evo_rpe kitti gt.kitti opt.kitti -v --plot --plot_mode xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commands to generate APE Error Graphs\n",
    "# evo_ape kitti gt.kitti opt.kitti -v --plot --plot_mode xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commands to generate TRAJ Error Graphs\n",
    "# evo_traj kitti gt.kitti opt.kitti -v --plot --plot_mode xy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mapfree",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
